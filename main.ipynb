{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/falarion08/CEPARCO_MP1/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Group 3\n",
        "Authors:\n",
        "\n",
        "Barrion, Ryan Onil\n",
        "\n",
        "Geronimo, Michael Robert\n",
        "\n",
        "Roledo, Jan Carlo\n",
        "\n",
        "Solis, Frances Danielle"
      ],
      "metadata": {
        "id": "xw2YPJrHJO9F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# C++ Version of Dot Product"
      ],
      "metadata": {
        "id": "AzxL1452tuan"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile c_dotp.c\n",
        "#include <bits/stdc++.h>\n",
        "#include <ctime>\n",
        "using namespace std;\n",
        "\n",
        "\n",
        "//C++ Dot Product Function\n",
        "void dot_product (int n, float h_out, float* h_in1, float* h_in2){\n",
        "  for (int i = 0; i < n; i++)\n",
        "   h_out += h_in1[i] * h_in2[i];\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const unsigned int ARRAY_SIZE = 1<<24;\n",
        "    const unsigned ARRRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
        "    const unsigned int run = 30;\n",
        "\n",
        "    float *in1, *in2, out;\n",
        "    in1 = (float*)malloc(ARRRAY_BYTES);\n",
        "    in2 = (float*)malloc(ARRRAY_BYTES);\n",
        "\n",
        "    clock_t start, end;\n",
        "\n",
        "    //init data\n",
        "    for(int i = 0; i <ARRAY_SIZE;i++){\n",
        "        in1[i]=float(i);\n",
        "        in2[i]=float(i);\n",
        "    }\n",
        "      \n",
        "    dot_product(ARRAY_SIZE, out,in1,in2);\n",
        "\n",
        "    start = clock();\n",
        "    for(int i = 0; i<run; i++){\n",
        "      dot_product(ARRAY_SIZE,out,in1,in2);\n",
        "    }\n",
        "    end = clock();\n",
        "    double time_taken = (((double)(end-start))* 1e6/CLOCKS_PER_SEC)/(double)run;\n",
        "    cout<< \"C++ function took an average of \"  << time_taken << \" microseconds for array size \" <<  ARRAY_SIZE;\n",
        "  \n",
        "    //Check for errors\n",
        "    \n",
        "    \n",
        "   \n",
        "   //free memory\n",
        "   free(in1);\n",
        "   free(in2);\n",
        "\n",
        "   return 0;\n",
        "\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ludT6zCltyGb",
        "outputId": "3c70f9a9-7d0d-4d3f-e976-1fa24fe5fa12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing c_dotp.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "g++ c_dotp.c -o c_dotp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKNDzn9pt1Ps",
        "outputId": "01193c2c-5a7c-4ac5-a8f3-59db20576f37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "./c_dotp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9j9VplQ_t23O",
        "outputId": "f906d0e4-a882-4941-9c6b-3b51490c13d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C++ function took an average of 59066 microseconds for array size 16777216"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "___\n",
        "#2. CUDA Without Cooperative Group Dot Product"
      ],
      "metadata": {
        "id": "9mxyL8vl65xT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cuda_uncooperative_threads.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "__global__\n",
        "void dotProduct(float *x,float *y, double *dotp,long unsigned int ARRAY_SIZE){\n",
        "\n",
        "  extern __shared__ double mul_result[];\n",
        "  mul_result[threadIdx.x]  = 0.0;\n",
        "\n",
        "\n",
        "  int index = blockIdx.x * gridDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "\n",
        "\n",
        "  for (int i = index; i < ARRAY_SIZE; i += stride){\n",
        "      mul_result[threadIdx.x] += (double)y[i] * x[i];\n",
        "  }\n",
        "  __syncthreads();\n",
        "\n",
        "  if(threadIdx.x == 0){\n",
        "    double sum = 0.0;\n",
        "\n",
        "    for(int i = 0 ; i < blockDim.x; ++i){\n",
        "      sum = sum + mul_result[i];\n",
        "    }\n",
        "    atomicAdd(dotp, sum);\n",
        "  }\n",
        "\n",
        "}\n",
        "int main(void){\n",
        "  // Declare Number of Elements\n",
        "  const unsigned long int ARRAY_SIZE = 1<<28;\n",
        "  const unsigned long int ARRAY_BYTES = ARRAY_SIZE * sizeof(ARRAY_SIZE); \n",
        "\n",
        "  // Declare Dimensions\n",
        "  const int nBlocks = 512;\n",
        "  const int nThreads = nBlocks;\n",
        "\n",
        "  int device = -1;\n",
        "  cudaGetDevice(&device);\n",
        "\n",
        "  float *x, *y;\n",
        "  double *dotp;\n",
        "\n",
        "  // Allocate resources for variables x and y;\n",
        "  cudaMallocManaged(&x,ARRAY_BYTES);\n",
        "  cudaMallocManaged(&y, ARRAY_BYTES);\n",
        "\n",
        "  // Allocate only a single space to store the result of sum\n",
        "  cudaMallocManaged(&dotp, sizeof(double));\n",
        "  *dotp = 0.0;\n",
        "  \n",
        "  //Prefetch Part 1\n",
        "  cudaMemAdvise(x,ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
        "  cudaMemAdvise(y,ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
        "\n",
        "  cudaMemPrefetchAsync(dotp,sizeof(double), device, NULL);\n",
        "\n",
        "  // Initialize Variables\n",
        "  for (int i = 0; i < ARRAY_SIZE; ++i){\n",
        "    x[i] = (float)((i + 1) % 50);\n",
        "    y[i]  = x[i] + 2.0;\n",
        "  }\n",
        "\n",
        "\n",
        "  // Prefetch Part 2\n",
        "  cudaMemAdvise(x, ARRAY_BYTES, cudaMemAdviseSetReadMostly, device);\n",
        "  cudaMemAdvise(y, ARRAY_BYTES, cudaMemAdviseSetReadMostly, device);\n",
        "\n",
        "  cudaMemAdvise(x, ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "  cudaMemAdvise(y, ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "\n",
        "  cudaMemPrefetchAsync(x,ARRAY_BYTES, device, NULL);\n",
        "  cudaMemPrefetchAsync(y,ARRAY_BYTES, device, NULL);\n",
        "\n",
        "  // Initial launch to prevent additional time for cache miss\n",
        "\n",
        "  //Launch Kernel\n",
        "  dotProduct<<<nBlocks,nThreads, sizeof(double) * nThreads>>>(x,y,dotp,ARRAY_SIZE);\n",
        "  cudaDeviceSynchronize();\n",
        "  \n",
        "  // Prefetch Result\n",
        "  cudaMemPrefetchAsync(dotp, sizeof(double), cudaCpuDeviceId, NULL);\n",
        "\n",
        "  // Check for Error by measuring percent error\n",
        "  double expected = 0;\n",
        "\n",
        "  for(int i = 0; i < ARRAY_SIZE; ++i){\n",
        "    expected = expected + (double)(x[i] * y[i]);\n",
        "  }\n",
        "\n",
        "  float pError = abs((dotp[0]-expected)/expected) * 100;\n",
        "\n",
        "  printf(\"\\n\\nNumber of Elements: %lu\\n\",ARRAY_SIZE);\n",
        "  printf(\"Number of Blocks: %d\\n\",nBlocks);\n",
        "  printf(\"Number of Threads: %d\\n\",nThreads);\n",
        "\n",
        "  printf(\"\\n\\nExpected:%f\\nComputed:%f\\n\\n\", dotp[0], expected );\n",
        "  printf(\"Percent Error: %f\\n\\n\",pError );\n",
        "\n",
        "  cudaFree(x);\n",
        "  cudaFree(y);\n",
        "  cudaFree(dotp);\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "NGwcHN8Z7HUi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d478b26b-7c68-4387-b49e-1a34d77641eb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting cuda_uncooperative_threads.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "nvcc cuda_uncooperative_threads.cu -o cuda_uncooperative_threads -arch=sm_60 \n",
        "\n",
        "nvprof ./cuda_uncooperative_threads\n"
      ],
      "metadata": {
        "id": "6CVhAjGp7KB3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3bcbce7-1c10-45e1-a652-a965fb3cb2bc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==2924== NVPROF is profiling process 2924, command: ./cuda_uncooperative_threads\n",
            "\n",
            "\n",
            "Number of Elements: 268435456\n",
            "Number of Blocks: 512\n",
            "Number of Threads: 512\n",
            "\n",
            "\n",
            "Expected:230183398508.000000\n",
            "Computed:230183398508.000000\n",
            "\n",
            "Percent Error: 0.000000\n",
            "\n",
            "==2924== Profiling application: ./cuda_uncooperative_threads\n",
            "==2924== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  9.9210ms         1  9.9210ms  9.9210ms  9.9210ms  dotProduct(float*, float*, double*, unsigned long)\n",
            "      API calls:   26.08%  166.34ms         3  55.446ms  3.1857ms  82.708ms  cudaFree\n",
            "                   22.81%  145.47ms         3  48.490ms  18.967us  145.40ms  cudaMallocManaged\n",
            "                   18.39%  117.29ms         1  117.29ms  117.29ms  117.29ms  cudaDeviceSynchronize\n",
            "                   16.58%  105.77ms         6  17.629ms  2.0800us  55.256ms  cudaMemAdvise\n",
            "                   16.11%  102.77ms         4  25.694ms  36.608us  102.38ms  cudaMemPrefetchAsync\n",
            "                    0.02%  112.90us       101  1.1170us     130ns  46.993us  cuDeviceGetAttribute\n",
            "                    0.01%  53.786us         1  53.786us  53.786us  53.786us  cudaLaunchKernel\n",
            "                    0.00%  28.166us         1  28.166us  28.166us  28.166us  cuDeviceGetName\n",
            "                    0.00%  5.8220us         1  5.8220us  5.8220us  5.8220us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.8530us         1  2.8530us  2.8530us  2.8530us  cudaGetDevice\n",
            "                    0.00%  1.5560us         3     518ns     155ns     985ns  cuDeviceGetCount\n",
            "                    0.00%  1.2890us         2     644ns     331ns     958ns  cuDeviceGet\n",
            "                    0.00%     783ns         1     783ns     783ns     783ns  cuDeviceTotalMem\n",
            "                    0.00%     417ns         1     417ns     417ns     417ns  cuModuleGetLoadingMode\n",
            "                    0.00%     254ns         1     254ns     254ns     254ns  cuDeviceGetUuid\n",
            "\n",
            "==2924== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "    1025  1.9981MB  4.0000KB  2.0000MB  2.000004GB  180.4207ms  Host To Device\n",
            "       1  4.0000KB  4.0000KB  4.0000KB  4.000000KB  1.632000us  Device To Host\n",
            "Total CPU Page faults: 1025\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#3. CUDA Cooperative Group Dot Product"
      ],
      "metadata": {
        "id": "Tf3h-SpKOw71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cuda_group.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <math.h>\n",
        "#include <cooperative_groups.h>\n",
        "\n",
        "using namespace cooperative_groups;\n",
        "namespace cg = cooperative_groups;\n",
        "\n",
        "#define BLOCK_SIZE 1024\n",
        "\n",
        "//device \"sub-function\" to fill shared memory and add elements in parallel\n",
        "__device__\n",
        "double reduction_dotprod(thread_block g, float *temp, float val_1, float val_2){\n",
        "\n",
        "  //get thread index\n",
        "  int lane = g.thread_rank();\n",
        "\n",
        "  val_1 = val_1 * val_2;\n",
        "  g.sync();\n",
        "\n",
        "  //\"Grid-Stride\" loop\n",
        "  for (int i = blockDim.x / 2; i > 0; i /= 2){        \n",
        "    temp[lane] = val_1;\n",
        "    g.sync();\n",
        "    if (lane < i) val_1 += temp[lane + i];\n",
        "    g.sync();\n",
        "  }\n",
        "\n",
        "  return val_1;\n",
        "}\n",
        "\n",
        "__global__\n",
        "void dotprod_group(float *in_x, float *in_y, double *out){\n",
        "\n",
        "  //create shared memory space\n",
        "  __shared__ float temp[BLOCK_SIZE];\n",
        "\n",
        "  //initialize thread block for binary-reduction sum\n",
        "  auto g = this_thread_block();\n",
        "\n",
        "  //assign thread with initial value from input vector\n",
        "  unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "  //perform reduction sum\n",
        "  double block_sum = reduction_dotprod(g, temp, in_x[i], in_y[i]);\n",
        "\n",
        "  //the first thread (thread 0) will have the final result\n",
        "  if (threadIdx.x == 0){\n",
        "    atomicAdd(out, block_sum);\n",
        "  }\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "int main() {\n",
        "\n",
        "  const unsigned int ARRAY_SIZE = 1<<24;\n",
        "\n",
        "  const unsigned int ARRAY_BYTES = ARRAY_SIZE * sizeof(int);\n",
        "\n",
        "  //size of shared bytes in sum_group() kernel\n",
        "  const unsigned int SHARED_BYTES = BLOCK_SIZE * sizeof(int);\n",
        "\n",
        "  const int NUM_BLOCKS = (ARRAY_SIZE + BLOCK_SIZE - 1) / BLOCK_SIZE;\n",
        "  printf(\"numElem = %d\\tnumThreads = %d\\tnumBlocks = %d\\n\", ARRAY_SIZE, BLOCK_SIZE, NUM_BLOCKS);\n",
        "\n",
        "  //declare ARRAY_BYTES or allocate in GPU\n",
        "  float *in_x, *in_y;\n",
        "  double *out;\n",
        "  cudaMallocManaged(&in_x, ARRAY_BYTES);\n",
        "  cudaMallocManaged(&in_y, ARRAY_BYTES);\n",
        "  cudaMallocManaged(&out, sizeof(double));\n",
        "\n",
        "  //prefetch input data to CPU\n",
        "  cudaMemPrefetchAsync(in_x, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
        "  cudaMemPrefetchAsync(in_y, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
        "\n",
        "  //init data\n",
        "  for(int i = 0; i < ARRAY_SIZE; i++)\n",
        "    in_x[i] = in_y[i] = 0.000001f * i;\n",
        "\n",
        "  int device = -1;\n",
        "  cudaGetDevice(&device); // get device number of GPU\n",
        "\n",
        "  cudaMemPrefetchAsync(out, ARRAY_BYTES, device, NULL);\n",
        "\n",
        "  //Prefetch and Memory Advise input data to device\n",
        "  cudaMemAdvise(in_x, ARRAY_BYTES, cudaMemAdviseSetReadMostly, device);\n",
        "  cudaMemPrefetchAsync(in_x, ARRAY_BYTES, device, NULL);\n",
        "\n",
        "  cudaMemAdvise(in_y, ARRAY_BYTES, cudaMemAdviseSetReadMostly, device);\n",
        "  cudaMemPrefetchAsync(in_y, ARRAY_BYTES, device, NULL);\n",
        "\n",
        "  cudaMemPrefetchAsync(out, sizeof(double), device, NULL);\n",
        "\n",
        "\n",
        "  //perform dot product with Cooperative Groups (thread_block)\n",
        "  dotprod_group<<<NUM_BLOCKS, BLOCK_SIZE, SHARED_BYTES>>> (in_x, in_y, out);\n",
        "\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "\n",
        "  //prefetch input data to CPU\n",
        "  cudaMemAdvise(in_x, ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "  cudaMemPrefetchAsync(in_x, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
        "\n",
        "  cudaMemAdvise(in_y, ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "  cudaMemPrefetchAsync(in_y, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
        "\n",
        "  cudaMemAdvise(out, sizeof(float), cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
        "  cudaMemPrefetchAsync(out, sizeof(float), cudaCpuDeviceId, NULL);\n",
        "\n",
        "  //check for errors\n",
        "  //NOTE: Floating point arithmetic is NOT ASSOCIATIVE\n",
        "  //todo: Match(?) adding order of algorithm\n",
        "  //may not actually be possible; blocks are always executed in any order\n",
        "  //and can't (as far as I'm aware) be set manually.\n",
        "  double sum = 0;\n",
        "  for(int i = 0; i < ARRAY_SIZE/2; i++) {\n",
        "    sum += (in_x[i] * in_y[i] + in_x[i+ARRAY_SIZE/2] * in_y[i+ARRAY_SIZE/2]);\n",
        "  }\n",
        "\n",
        "  double sum_seq = 0;\n",
        "  for (int i = 0; i < ARRAY_SIZE; i++){\n",
        "    sum_seq += in_x[i] * in_y[i];\n",
        "  }\n",
        "  printf(\"Sequential Sum: %lf\\t\", sum_seq);\n",
        "  printf(\"'Binary Split' Sum: %lf\\t Coop-Group Reduction Sum: %lf\\n\",sum, *out);\n",
        "\n",
        "  double diff = abs((*out - sum) / sum) * 100.0;\n",
        "\n",
        "  printf(\"Difference with split sum: %.5f%%\\n\", diff);\n",
        "\n",
        "  //free memory in GPU\n",
        "  cudaFree(in_x);\n",
        "  cudaFree(in_y);\n",
        "  cudaFree(out);\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11c2c15b-7074-4f98-b50c-18a102ca9967",
        "id": "94MPcY77v2uL"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cuda_group.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc cuda_group.cu -o cuda_group -arch=sm_60"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdf531aa-5c12-40b5-9a9d-fd96294f9a86",
        "id": "gG_mzcEgv2uQ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvprof ./cuda_group"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00162bfe-224f-48af-c139-ec3818abcd2e",
        "id": "oxwnn-rAv2uQ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numElem = 16777216\tnumThreads = 1024\tnumBlocks = 16384\n",
            "==695== NVPROF is profiling process 695, command: ./cuda_group\n",
            "Sequential Sum: 1574122012.273521\t'Binary Split' Sum: 1574122012.255829\t Coop-Group Reduction Sum: 1574122011.782480\n",
            "Difference with split sum: 0.00000%\n",
            "==695== Profiling application: ./cuda_group\n",
            "==695== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  2.7659ms         1  2.7659ms  2.7659ms  2.7659ms  dotprod_group(float*, float*, double*)\n",
            "      API calls:   78.54%  233.94ms         3  77.981ms  17.951us  233.88ms  cudaMallocManaged\n",
            "                   14.14%  42.109ms         9  4.6787ms  7.4060us  17.234ms  cudaMemPrefetchAsync\n",
            "                    2.99%  8.9173ms         3  2.9724ms  99.315us  4.4375ms  cudaFree\n",
            "                    2.28%  6.7977ms         5  1.3595ms  1.5290us  3.4656ms  cudaMemAdvise\n",
            "                    1.57%  4.6651ms         1  4.6651ms  4.6651ms  4.6651ms  cudaDeviceSynchronize\n",
            "                    0.40%  1.1780ms         1  1.1780ms  1.1780ms  1.1780ms  cuDeviceGetPCIBusId\n",
            "                    0.06%  175.34us       101  1.7360us     127ns  69.376us  cuDeviceGetAttribute\n",
            "                    0.02%  58.335us         1  58.335us  58.335us  58.335us  cudaLaunchKernel\n",
            "                    0.01%  27.347us         1  27.347us  27.347us  27.347us  cuDeviceGetName\n",
            "                    0.00%  5.5170us         1  5.5170us  5.5170us  5.5170us  cudaGetDevice\n",
            "                    0.00%  2.0990us         3     699ns     242ns  1.4970us  cuDeviceGetCount\n",
            "                    0.00%  1.0970us         2     548ns     269ns     828ns  cuDeviceGet\n",
            "                    0.00%     667ns         1     667ns     667ns     667ns  cuDeviceTotalMem\n",
            "                    0.00%     624ns         1     624ns     624ns     624ns  cuModuleGetLoadingMode\n",
            "                    0.00%     320ns         1     320ns     320ns     320ns  cuDeviceGetUuid\n",
            "\n",
            "==695== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "      64  2.0000MB  2.0000MB  2.0000MB  128.0000MB  11.19087ms  Host To Device\n",
            "       1  4.0000KB  4.0000KB  4.0000KB  4.000000KB  2.048000us  Device To Host\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}